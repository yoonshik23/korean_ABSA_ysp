{"cells":[{"cell_type":"code","source":["# https://pytorch.org/ cuda 설치, pytorch 설치 \n","# !conda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia"],"metadata":{"id":"xmQrC8kKw_hP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install sklearn"],"metadata":{"id":"LTLIcp6tw795"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2991,"status":"ok","timestamp":1668241606223,"user":{"displayName":"박윤식","userId":"16877335343800304841"},"user_tz":-540},"id":"_RDH-YQsQ2K0","outputId":"26940dc6-b26e-44c4-9d58-71c11c6772fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"jprcZhTyetFF"},"source":["# 모듈 import 및 전역 변수 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2138,"status":"ok","timestamp":1668241608359,"user":{"displayName":"박윤식","userId":"16877335343800304841"},"user_tz":-540},"id":"sOqphmOMJWlQ","outputId":"2f31baa0-641b-4f67-aaf9-d65f421bf6e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# 코랩에서 실행 시 drive 마운트\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8LDwADWNMpsC"},"outputs":[],"source":["import json\n","import os\n","\n","import torch\n","import torch.nn as nn\n","from tqdm import trange\n","\n","from transformers import AutoTokenizer, AutoModel\n","from torch.utils.data import DataLoader, TensorDataset\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import AdamW\n","\n","from sklearn.metrics import f1_score\n","import pandas as pd\n","import numpy as np\n","import copy\n","\n","import random\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","\n","import pickle\n","\n","for_test = True\n","\n","PADDING_TOKEN = 1\n","S_OPEN_TOKEN = 0\n","S_CLOSE_TOKEN = 2\n","\n","do_eval=True\n","FULL_FINETUNING = True\n","category_extraction_model_path = '/content/drive/MyDrive/게임/korean_ABSA_baseline-main/saved_model5/category_extraction'\n","polarity_classification_model_path = '/content/drive/MyDrive/게임/korean_ABSA_baseline-main/saved_model5/polarity_classification'\n","\n","\n","train_data_path = '/content/drive/MyDrive/게임/korean_ABSA_baseline-main/data/nikluge-sa-2022-train.jsonl'\n","dev_data_path = '/content/drive/MyDrive/게임/korean_ABSA_baseline-main/data/nikluge-sa-2022-dev.jsonl'\n","test_data_path = '/content/drive/MyDrive/게임/korean_ABSA_baseline-main/data/nikluge-sa-2022-test.jsonl'\n","\n","\n","\n","max_len = 256\n","batch_size = 8\n","# base_model = 'xlm-roberta-base'\n","base_model = 'klue/roberta-large'\n","entity_property_learning_rate = 3e-6\n","polarity_learning_rate = 3e-6\n","eps = 1e-8\n","num_train_epochs = 100\n","classifier_hidden_size = 768\n","classifier_dropout_prob = 0.1\n","\n","entity_property_patience_ub = 10\n","polarity_patience_ub = 10\n","val_num = 5\n","\n","entity_property_pair = ['본품#품질',\n","'제품 전체#일반',\n","'제품 전체#품질',\n","'본품#일반',\n","'제품 전체#디자인',\n","'본품#편의성',\n","'제품 전체#편의성',\n","'제품 전체#인지도',\n","'패키지/구성품#디자인',\n","'브랜드#일반',\n","'제품 전체#가격',\n","'패키지/구성품#편의성',\n","'패키지/구성품#일반',\n","# '본품#다양성',\n","# '본품#디자인',\n","# '브랜드#품질',\n","# '패키지/구성품#품질',\n","# '브랜드#인지도',\n","# '브랜드#가격',\n","# '패키지/구성품#다양성',\n","# '본품#가격',\n","# '본품#인지도',\n","# '패키지/구성품#가격'\n","]\n","\n","tf_id_to_name = ['True', 'False']\n","tf_id_to_name = ['본품#품질',\n","'제품 전체#일반',\n","'제품 전체#품질',\n","'본품#일반',\n","'제품 전체#디자인',\n","'본품#편의성',\n","'제품 전체#편의성',\n","'제품 전체#인지도',\n","'패키지/구성품#디자인',\n","'브랜드#일반',\n","'제품 전체#가격',\n","'패키지/구성품#편의성',\n","'패키지/구성품#일반',\n","# '본품#다양성',\n","# '본품#디자인',\n","# '브랜드#품질',\n","# '패키지/구성품#품질',\n","# '브랜드#인지도',\n","# '브랜드#가격',\n","# '패키지/구성품#다양성',\n","# '본품#가격',\n","# '본품#인지도',\n","# '패키지/구성품#가격'\n","]\n","tf_name_to_id = {tf_id_to_name[i]: i for i in range(len(tf_id_to_name))}\n","\n","polarity_id_to_name = ['positive', 'neutral', 'negative']\n","polarity_name_to_id = {polarity_id_to_name[i]: i for i in range(len(polarity_id_to_name))}\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","special_tokens_dict = {\n","    'additional_special_tokens': ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n","}"]},{"cell_type":"markdown","metadata":{"id":"xGmH15hCeqhJ"},"source":["json 및 jsonl 파일 read, write 함수"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1668241611665,"user":{"displayName":"박윤식","userId":"16877335343800304841"},"user_tz":-540},"id":"6vGeHU4yP2Sg","outputId":"316d6d3b-13c9-4591-899a-4a513e3c742c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'id': 'nikluge-sa-2022-train-00001',\n","  'sentence_form': '둘쨋날은 미친듯이 밟아봤더니 기어가 헛돌면서 틱틱 소리가 나서 경악.',\n","  'annotation': [['본품#품질', ['기어', 16, 18], 'negative']]},\n"," {'id': 'nikluge-sa-2022-train-00002',\n","  'sentence_form': '이거 뭐 삐꾸를 준 거 아냐 불안하고, 거금 투자한 게 왜 이래.. 싶어서 정이 확 떨어졌는데 산 곳 가져가서 확인하니 기어 텐션 문제라고 고장 아니래.',\n","  'annotation': [['본품#품질', ['기어 텐션', 67, 72], 'negative']]},\n"," {'id': 'nikluge-sa-2022-train-00003',\n","  'sentence_form': '간사하게도 그 이후에는 라이딩이 아주 즐거워져서 만족스럽게 탔다.',\n","  'annotation': [['제품 전체#일반', [None, 0, 0], 'positive']]},\n"," {'id': 'nikluge-sa-2022-train-00004',\n","  'sentence_form': '샥이 없는 모델이라 일반 도로에서 타면 노면의 진동 때문에 손목이 덜덜덜 떨리고 이가 부딪칠 지경인데 이마저도 며칠 타면서 익숙해지니 신경쓰이지 않게 됐다.',\n","  'annotation': [['제품 전체#일반', ['샥이 없는 모델', 0, 8], 'neutral']]},\n"," {'id': 'nikluge-sa-2022-train-00005',\n","  'sentence_form': '안장도 딱딱해서 엉덩이가 아팠는데 무시하고 타고 있다.',\n","  'annotation': [['본품#일반', ['안장', 0, 2], 'negative']]},\n"," {'id': 'nikluge-sa-2022-train-00006',\n","  'sentence_form': '지금 내 실력과 저질 체력으로는 이 정도 자전거도 되게 훌륭한 거라는..',\n","  'annotation': [['제품 전체#일반', ['자전거', 23, 26], 'positive']]},\n"," {'id': 'nikluge-sa-2022-train-00007',\n","  'sentence_form': '내장 기어 3단은 썩 좋은 물건이라 기어 변환도 부드럽고 겉에서는 기어가 보이지 않기 때문에 깔끔하다.',\n","  'annotation': [['본품#품질', ['내장 기어 3단', 0, 8], 'positive']]},\n"," {'id': 'nikluge-sa-2022-train-00008',\n","  'sentence_form': '한번 교환했는데 새로 온 UD20은 불량화소가 있고 ㅜ ㅜ ㅜ',\n","  'annotation': [['본품#품질', ['UD20', 14, 18], 'negative']]},\n"," {'id': 'nikluge-sa-2022-train-00009',\n","  'sentence_form': '전에 작동 안되었던 자막 검색 후 등록 기능이 똑같이 작동 안 된다!!!',\n","  'annotation': [['본품#품질', ['자막 검색 후 등록 기능', 11, 24], 'negative']]},\n"," {'id': 'nikluge-sa-2022-train-00010',\n","  'sentence_form': '왜 [등록]키를 만들어놓고 제대로 단어장에 등록이 되지 않는 거냐!!',\n","  'annotation': [['본품#품질', ['등록]키', 3, 7], 'negative']]},\n"," {'id': 'nikluge-sa-2022-train-00011',\n","  'sentence_form': '다른 부가 기능은 참 훌륭한데..',\n","  'annotation': [['본품#품질', ['부가 기능', 3, 8], 'positive']]},\n"," {'id': 'nikluge-sa-2022-train-00012',\n","  'sentence_form': '미치겠네.',\n","  'annotation': [['제품 전체#일반', [None, 0, 0], 'negative']]},\n"," {'id': 'nikluge-sa-2022-train-00013',\n","  'sentence_form': '아.. 진짜 기계 사겠나.',\n","  'annotation': [['제품 전체#일반', [None, 0, 0], 'negative']]},\n"," {'id': 'nikluge-sa-2022-train-00014',\n","  'sentence_form': '이번에는 사전까지..',\n","  'annotation': [['제품 전체#일반', [None, 0, 0], 'negative']]},\n"," {'id': 'nikluge-sa-2022-train-00015',\n","  'sentence_form': '이런 젠장..',\n","  'annotation': [['제품 전체#일반', [None, 0, 0], 'negative']]}]"]},"metadata":{},"execution_count":13}],"source":["def jsonload(fname, encoding=\"utf-8\"):\n","    with open(fname, encoding=encoding) as f:\n","        j = json.load(f)\n","\n","    return j\n","\n","\n","# json 개체를 파일이름으로 깔끔하게 저장\n","def jsondump(j, fname):\n","    with open(fname, \"w\", encoding=\"UTF8\") as f:\n","        json.dump(j, f, ensure_ascii=False)\n","\n","# jsonl 파일 읽어서 list에 저장\n","def jsonlload(fname, encoding=\"utf-8\"):\n","    json_list = []\n","    with open(fname, encoding=encoding) as f:\n","        for line in f.readlines():\n","            json_list.append(json.loads(line))\n","    return json_list\n","\n","\n","# jsonlload('/content/drive/MyDrive/게임/korean_ABSA_baseline-main/data/sample.jsonl')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":3722,"status":"ok","timestamp":1668241615385,"user":{"displayName":"박윤식","userId":"16877335343800304841"},"user_tz":-540},"id":"o4uIdLLDNeEK","outputId":"8991a75c-2e76-4c85-a3af-33f3143d8500"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     entity_property  polarity\n","0              본품#품질  negative\n","1              본품#품질  negative\n","2           제품 전체#일반  positive\n","3           제품 전체#일반   neutral\n","4              본품#일반  negative\n","...              ...       ...\n","6329      패키지/구성품#일반  positive\n","6330        제품 전체#가격  negative\n","6331        제품 전체#가격  negative\n","6332        제품 전체#일반  positive\n","6333        제품 전체#품질  positive\n","\n","[6334 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-4c22f6f6-e8e8-4ff5-b7df-e74d0c92f47f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>entity_property</th>\n","      <th>polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>본품#품질</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>본품#품질</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>제품 전체#일반</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>제품 전체#일반</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>본품#일반</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6329</th>\n","      <td>패키지/구성품#일반</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>6330</th>\n","      <td>제품 전체#가격</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>6331</th>\n","      <td>제품 전체#가격</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>6332</th>\n","      <td>제품 전체#일반</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>6333</th>\n","      <td>제품 전체#품질</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6334 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c22f6f6-e8e8-4ff5-b7df-e74d0c92f47f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4c22f6f6-e8e8-4ff5-b7df-e74d0c92f47f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4c22f6f6-e8e8-4ff5-b7df-e74d0c92f47f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}],"source":["tmp_list = jsonlload(train_data_path)\n","tmp_list.extend(jsonlload(dev_data_path))\n","tmp_df = pd.DataFrame()\n","k=0\n","for i in range(len(tmp_list)):\n","  for j in range(len(tmp_list[i]['annotation'])):\n","    tmp_df.loc[k,'entity_property'] = tmp_list[i]['annotation'][j][0]\n","    tmp_df.loc[k,'polarity'] = tmp_list[i]['annotation'][j][-1]\n","    k+=1\n","tmp_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1668241615385,"user":{"displayName":"박윤식","userId":"16877335343800304841"},"user_tz":-540},"id":"QB_0RPZYO58y","outputId":"08d944c9-c640-4fde-bc5e-e2a07bb67e8e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["본품#품질          2380\n","제품 전체#일반       1624\n","제품 전체#품질        493\n","본품#일반           491\n","제품 전체#디자인       286\n","본품#편의성          191\n","제품 전체#편의성       180\n","제품 전체#인지도       141\n","패키지/구성품#디자인     117\n","브랜드#일반          103\n","제품 전체#가격         92\n","패키지/구성품#편의성      65\n","패키지/구성품#일반       50\n","본품#다양성           31\n","본품#디자인           21\n","브랜드#품질           19\n","패키지/구성품#품질       19\n","브랜드#인지도          17\n","브랜드#가격            7\n","패키지/구성품#다양성       3\n","본품#가격             2\n","본품#인지도            1\n","패키지/구성품#가격        1\n","Name: entity_property, dtype: int64"]},"metadata":{},"execution_count":15}],"source":["tmp_df['entity_property'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1668241615385,"user":{"displayName":"박윤식","userId":"16877335343800304841"},"user_tz":-540},"id":"gcdCwPhbOikM","outputId":"3e5898a3-6d6b-4113-c242-01bcd1593231"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2.5540322580645163,\n"," 3.6740139211136893,\n"," 10.681281618887015,\n"," 10.717428087986464,\n"," 16.409326424870468,\n"," 21.766323024054984,\n"," 22.62142857142857,\n"," 26.282157676348547,\n"," 29.1889400921659,\n"," 31.201970443349754,\n"," 32.989583333333336,\n"," 38.38787878787879,\n"," 42.22666666666667,\n"," 48.35114503816794,\n"," 52.34710743801653,\n"," 53.226890756302524,\n"," 53.226890756302524,\n"," 54.136752136752136,\n"," 59.19626168224299,\n"," 61.49514563106796,\n"," 62.09803921568628,\n"," 62.71287128712871,\n"," 62.71287128712871]"]},"metadata":{},"execution_count":16}],"source":["import numpy as np\n","class_weight = list(len(tmp_df['entity_property'])/(tmp_df['entity_property'].value_counts()+100)) # entity_property의 각각 label의 positive에 대해 줄 가중치샘플비율대로 하면 너무 심해서 로그씌움.\n","class_weight"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1668241615385,"user":{"displayName":"박윤식","userId":"16877335343800304841"},"user_tz":-540},"id":"CglatIEyeEpV","outputId":"ef8f6e33-efc3-4f2c-d9ea-cfb4a0095b86"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2.5540322580645163,\n"," 3.6740139211136893,\n"," 10.681281618887015,\n"," 10.717428087986464,\n"," 16.409326424870468,\n"," 21.766323024054984,\n"," 22.62142857142857,\n"," 26.282157676348547,\n"," 29.1889400921659,\n"," 31.201970443349754,\n"," 32.989583333333336,\n"," 38.38787878787879,\n"," 42.22666666666667]"]},"metadata":{},"execution_count":17}],"source":["import numpy as np\n","class_weight = list(len(tmp_df['entity_property'])/(tmp_df['entity_property'].value_counts()+100)) # entity_property의 각각 label의 positive에 대해 줄 가중치샘플비율대로 하면 너무 심해서 로그씌움.\n","class_weight = class_weight[:-10]\n","class_weight"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1668241615386,"user":{"displayName":"박윤식","userId":"16877335343800304841"},"user_tz":-540},"id":"LzNgYUJg4oUX","outputId":"f1b6d5e9-08be-433e-ed16-822c8c627e33"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.0385309067060173, 42.51006711409396, 73.65116279069767]"]},"metadata":{},"execution_count":18}],"source":["polarity_class_weight = list(len(tmp_df['polarity'])/tmp_df['polarity'].value_counts())\n","polarity_class_weight"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1668241615386,"user":{"displayName":"박윤식","userId":"16877335343800304841"},"user_tz":-540},"id":"i01P6V3TeH5L","outputId":"c335a1ee-5df5-4f21-e30a-72bd75025e26"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.0190833659254857, 6.5199744718897445, 8.582025564556288]"]},"metadata":{},"execution_count":19}],"source":["polarity_class_weight = list(np.sqrt(len(tmp_df['polarity'])/(tmp_df['polarity'].value_counts())))\n","polarity_class_weight"]},{"cell_type":"markdown","metadata":{"id":"xuHV8HGqXvg_"},"source":["# 모델 정의\n","roberta large 모델을 기반으로 한 classification 모델 이용"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WkyrAEhAQBQV"},"outputs":[],"source":["class SimpleClassifier(nn.Module):\n","\n","    def __init__(self, num_label):\n","        super().__init__()\n","        # self.dense = nn.Linear(classifier_hidden_size, classifier_hidden_size)\n","        self.dense = nn.Linear(1024, 50)\n","        self.dropout = nn.Dropout(classifier_dropout_prob)\n","        self.output = nn.Linear(50, num_label)\n","\n","    def forward(self, features):\n","        x = features[:, 0, :]\n","        x = self.dropout(x)\n","        x = self.dense(x)\n","        x = torch.tanh(x)\n","        x = self.dropout(x)\n","        x = self.output(x)\n","        return x\n","\n","\n","class RoBertaBaseClassifier(nn.Module):\n","    def __init__(self, num_label, len_tokenizer):\n","        super(RoBertaBaseClassifier, self).__init__()\n","\n","        self.num_label = num_label\n","        self.xlm_roberta = AutoModel.from_pretrained(base_model)\n","        for param in self.xlm_roberta.parameters():\n","            param.requires_grad = False\n","\n","        self.xlm_roberta.resize_token_embeddings(len_tokenizer)\n","\n","        self.labels_classifier = SimpleClassifier(self.num_label)\n","\n","    def forward(self, input_ids, attention_mask, labels=None):\n","        outputs = self.xlm_roberta(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=None\n","        )\n","\n","        sequence_output = outputs[0]\n","        logits = self.labels_classifier(sequence_output)\n","\n","        # logits = torch.sigmoid(logits)\n","\n","        loss = None\n","\n","        if labels is not None:\n","            loss_fct = nn.BCEWithLogitsLoss(\n","                pos_weight=torch.tensor(class_weight).to(device)\n","                )\n","            loss = loss_fct(logits.view(-1, self.num_label),\n","                                                labels)\n","        # logits = torch.sigmoid(logits)\n","\n","        return loss, logits\n","\n","class RoBertaBaseClassifier_polar(nn.Module):\n","    def __init__(self, num_label, len_tokenizer):\n","        super(RoBertaBaseClassifier_polar, self).__init__()\n","\n","        self.num_label = num_label\n","        self.xlm_roberta = AutoModel.from_pretrained(base_model)\n","        for param in self.xlm_roberta.parameters():\n","            param.requires_grad = False\n","\n","        self.xlm_roberta.resize_token_embeddings(len_tokenizer)\n","\n","        self.labels_classifier = SimpleClassifier(self.num_label)\n","\n","    def forward(self, input_ids, attention_mask, labels=None):\n","        outputs = self.xlm_roberta(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=None\n","        )\n","\n","        sequence_output = outputs[0]\n","        logits = self.labels_classifier(sequence_output)\n","\n","        loss = None\n","\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss(\n","                weight=torch.tensor(polarity_class_weight).to(device)\n","                )\n","            loss = loss_fct(logits.view(-1, self.num_label),\n","                                                labels.view(-1))\n","\n","        return loss, logits\n"]},{"cell_type":"markdown","metadata":{"id":"q-p0LKeGi194"},"source":["# 데이터 파싱 및 tokenization 함수 정의\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XO-hv7lQQGA5"},"outputs":[],"source":["\n","def tokenize_and_align_labels(tokenizer, form, annotations, max_len):\n","\n","    entity_property_data_dict = {\n","        'input_ids': [],\n","        'attention_mask': [],\n","        'label': []\n","    }\n","    polarity_data_dict = {\n","        'input_ids': [],\n","        'attention_mask': [],\n","        'label': []\n","    }\n","    tokenized_data = tokenizer(form, '미정', padding='max_length', max_length=max_len, truncation=True)\n","    entity_property_data_dict['input_ids'].append(tokenized_data['input_ids'])\n","    entity_property_data_dict['attention_mask'].append(tokenized_data['attention_mask'])\n","    entity_property_data_dict['label'].append([0.0]*13)\n","    isPairInOpinion = False\n","    for pair in entity_property_pair:\n","        \n","        if pd.isna(form):\n","            break\n","        \n","\n","        for annotation in annotations:\n","            entity_property = annotation[0]\n","            polarity = annotation[2]\n","\n","            if polarity == '------------':\n","                continue\n","\n","            if entity_property == pair:\n","                entity_property_data_dict['label'][-1][tf_name_to_id[entity_property]] = 1.0\n","\n","                tokenized_data = tokenizer(form, pair, padding='max_length', max_length=max_len, truncation=True)\n","                polarity_data_dict['input_ids'].append(tokenized_data['input_ids'])\n","                polarity_data_dict['attention_mask'].append(tokenized_data['attention_mask'])\n","                polarity_data_dict['label'].append(polarity_name_to_id[polarity])\n","\n","                break\n","\n","\n","    return entity_property_data_dict, polarity_data_dict\n","\n","\n","def get_dataset(raw_data, tokenizer, max_len):\n","    input_ids_list = []\n","    attention_mask_list = []\n","    token_labels_list = []\n","\n","    polarity_input_ids_list = []\n","    polarity_attention_mask_list = []\n","    polarity_token_labels_list = []\n","\n","    for utterance in raw_data:\n","        entity_property_data_dict, polarity_data_dict = tokenize_and_align_labels(tokenizer, utterance['sentence_form'], utterance['annotation'], max_len)\n","        input_ids_list.extend(entity_property_data_dict['input_ids'])\n","        attention_mask_list.extend(entity_property_data_dict['attention_mask'])\n","        token_labels_list.extend(entity_property_data_dict['label'])\n","\n","        polarity_input_ids_list.extend(polarity_data_dict['input_ids'])\n","        polarity_attention_mask_list.extend(polarity_data_dict['attention_mask'])\n","        polarity_token_labels_list.extend(polarity_data_dict['label'])\n","\n","    return TensorDataset(torch.tensor(input_ids_list), torch.tensor(attention_mask_list),\n","                         torch.tensor(token_labels_list)), TensorDataset(torch.tensor(polarity_input_ids_list), torch.tensor(polarity_attention_mask_list),\n","                         torch.tensor(polarity_token_labels_list))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5Ka98lsxi--Y"},"source":["# 모델 학습"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B_Ebvu6TQdBA"},"outputs":[],"source":["# evaluation에 5-fold 정도로 dev 나눠서 시행하고, 성능 감소하면 full 학습으로 변경, 2연속 감소하면 중단. 5개 평균으로 예측하게 변경하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CTItiOg6j7t1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YL0yp7zSaX9B"},"outputs":[],"source":["\n","def train_sentiment_analysis():\n","\n","    print('train_sentiment_analysis')\n","    print('category_extraction model would be saved at ', category_extraction_model_path)\n","    print('polarity model would be saved at ', polarity_classification_model_path)\n","\n","    print('loading train data')\n","\n","    train_data = jsonlload(train_data_path)\n","    train_data.extend(jsonlload(dev_data_path))\n","    tmp_df = pd.DataFrame()\n","    tmp_train = []\n","    k=0\n","    for i in range(len(train_data)):\n","      if train_data[i]['annotation'][0][0] in entity_property_pair:\n","        tmp_train.append(train_data[i])\n","        tmp_df.loc[k,'entity_property'] = train_data[i]['annotation'][0][0]\n","        k += 1\n","    from sklearn.model_selection import StratifiedKFold\n","    skf = StratifiedKFold(n_splits=5, random_state = 0, shuffle=True)\n","    val_step = 0\n","    for train_index, test_index in skf.split(tmp_train, tmp_df['entity_property']):\n","      print('\\n\\n======================= {} step=========================\\n\\n\\n\\n\\n\\n\\n\\n'.format(val_step+1))\n","      tmp_dev_data = []\n","      tmp_train_data = []\n","      for i in test_index:\n","        tmp_dev_data.append(tmp_train[i])\n","      for i in train_index:\n","        tmp_train_data.append(tmp_train[i])\n","\n","\n","      entity_property_val_best_loss = 100\n","\n","      print('tokenizing train data')\n","      tokenizer = AutoTokenizer.from_pretrained(base_model)\n","      num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n","      print('We have added', num_added_toks, 'tokens')\n","      entity_property_train_data, polarity_train_data = get_dataset(tmp_train_data, tokenizer, max_len)\n","      entity_property_dev_data, polarity_dev_data = get_dataset(tmp_dev_data, tokenizer, max_len)\n","      entity_property_train_dataloader = DataLoader(entity_property_train_data, shuffle=True,\n","                                    batch_size=batch_size)\n","      entity_property_dev_dataloader = DataLoader(entity_property_dev_data, shuffle=True,\n","                                  batch_size=batch_size)\n","      \n","      print('loading model')\n","      entity_property_model = RoBertaBaseClassifier(len(tf_id_to_name), len(tokenizer))\n","      entity_property_model.to(device)\n","\n","      print('end loading')\n","\n","      # entity_property_model_optimizer_setting\n","      FULL_FINETUNING = True\n","      if FULL_FINETUNING:\n","          entity_property_param_optimizer = list(entity_property_model.named_parameters())\n","          no_decay = ['bias', 'gamma', 'beta']\n","          entity_property_optimizer_grouped_parameters = [\n","              {'params': [p for n, p in entity_property_param_optimizer if not any(nd in n for nd in no_decay)],\n","              'weight_decay_rate': 0.01},\n","              {'params': [p for n, p in entity_property_param_optimizer if any(nd in n for nd in no_decay)],\n","              'weight_decay_rate': 0.0}\n","          ]\n","      else:\n","          entity_property_param_optimizer = list(entity_property_model.classifier.named_parameters())\n","          entity_property_optimizer_grouped_parameters = [{\"params\": [p for n, p in entity_property_param_optimizer]}]\n","\n","      entity_property_optimizer = AdamW(\n","          entity_property_optimizer_grouped_parameters,\n","          lr=entity_property_learning_rate,\n","          eps=eps\n","      )\n","      epochs = num_train_epochs\n","      max_grad_norm = 1.0\n","      total_steps = epochs * len(entity_property_train_dataloader)\n","\n","      entity_property_scheduler = get_linear_schedule_with_warmup(\n","          entity_property_optimizer,\n","          num_warmup_steps=0,\n","          num_training_steps=total_steps\n","      )\n","\n","      epoch_step = 0\n","      entity_property_patience = 0\n","\n","      for _ in trange(epochs, desc=\"Epoch\"):\n","          \n","          entity_property_model.train()\n","          epoch_step += 1\n","          if entity_property_patience == int(entity_property_patience_ub*3/5):\n","              model_load_path = category_extraction_model_path + 'saved_model_epoch_' + str(val_step) + '.pt'\n","              entity_property_model.load_state_dict(torch.load(model_load_path, map_location=device))\n","              entity_property_model.to(device)\n","              for param in entity_property_model.xlm_roberta.parameters():\n","                  param.requires_grad = True\n","              entity_property_model.train()\n","\n","          # entity_property train\n","          entity_property_total_loss = 0\n","          if entity_property_patience <= entity_property_patience_ub:\n","              for step, batch in enumerate(entity_property_train_dataloader):\n","                  batch = tuple(t.to(device) for t in batch)\n","                  b_input_ids, b_input_mask, b_labels = batch\n","\n","                  entity_property_model.zero_grad()\n","                  # print('b_labels: ', b_labels)\n","                  loss, _ = entity_property_model(b_input_ids, b_input_mask, b_labels)\n","\n","                  loss.backward()\n","\n","                  entity_property_total_loss += loss.item()\n","                  # print('batch_loss: ', loss.item())\n","\n","                  torch.nn.utils.clip_grad_norm_(parameters=entity_property_model.parameters(), max_norm=max_grad_norm)\n","                  entity_property_optimizer.step()\n","                  entity_property_scheduler.step()\n","\n","              avg_train_loss = entity_property_total_loss / len(entity_property_train_dataloader)\n","              print(\"Entity_Property_Epoch: \", epoch_step)\n","              print(\"Average train loss: {}\".format(avg_train_loss))\n","\n","\n","\n","              if do_eval:\n","                  entity_property_model.eval()\n","\n","                  pred_list = []\n","                  label_list = []\n","                  loss_list = []\n","                  for batch in entity_property_dev_dataloader:\n","                      batch = tuple(t.to(device) for t in batch)\n","                      b_input_ids, b_input_mask, b_labels = batch\n","\n","                      with torch.no_grad():\n","                          loss, logits = entity_property_model(b_input_ids, b_input_mask, b_labels)\n","                          loss_list.append(loss.item())\n","                  print('validation error: ', np.mean(loss_list))\n","                  if np.mean(loss_list) < entity_property_val_best_loss:\n","\n","                      entity_property_val_best_loss = np.mean(loss_list)\n","                      model_saved_path = category_extraction_model_path + 'saved_model_epoch_' + str(val_step) + '.pt'\n","                      torch.save(entity_property_model.state_dict(), model_saved_path)\n","                      print('entity_property_model best model updated.')\n","                      entity_property_patience = 0\n","                  else:\n","                      entity_property_patience += 1\n","\n","      val_step += 1\n","\n","\n","    train_data = jsonlload(train_data_path)\n","    train_data.extend(jsonlload(dev_data_path))\n","\n","    tmp_df = pd.DataFrame()\n","    for i in range(len(train_data)):\n","      tmp_df.loc[i,'polarity'] = train_data[i]['annotation'][0][-1]\n","\n","    skf = StratifiedKFold(n_splits=5, random_state = 0, shuffle=True)\n","    val_step = 0\n","    for train_index, test_index in skf.split(train_data, tmp_df['polarity']):\n","      tmp_dev_data = []\n","      tmp_train_data = []\n","      for i in test_index:\n","        tmp_dev_data.append(train_data[i])\n","      for i in train_index:\n","        tmp_train_data.append(train_data[i])\n","\n","      polarity_val_best_loss = 100\n","      print('\\n\\n======================= {} step=========================\\n\\n\\n\\n\\n\\n\\n\\n'.format(val_step+1))\n","\n","      print('tokenizing train data')\n","      tokenizer = AutoTokenizer.from_pretrained(base_model)\n","      num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n","      print('We have added', num_added_toks, 'tokens')\n","\n","      entity_property_train_data, polarity_train_data = get_dataset(tmp_train_data, tokenizer, max_len)\n","      entity_property_dev_data, polarity_dev_data = get_dataset(tmp_dev_data, tokenizer, max_len)\n","      \n","      polarity_train_dataloader = DataLoader(polarity_train_data, shuffle=True,\n","                                                    batch_size=batch_size)\n","      polarity_dev_dataloader = DataLoader(polarity_dev_data, shuffle=True,\n","                                                  batch_size=batch_size)\n","\n","      print('loading model')\n","      polarity_model = RoBertaBaseClassifier_polar(len(polarity_id_to_name), len(tokenizer))\n","      polarity_model.to(device)\n","\n","\n","      print('end loading')\n","      # polarity_model_optimizer_setting\n","      if FULL_FINETUNING:\n","          polarity_param_optimizer = list(polarity_model.named_parameters())\n","          no_decay = ['bias', 'gamma', 'beta']\n","          polarity_optimizer_grouped_parameters = [\n","              {'params': [p for n, p in polarity_param_optimizer if not any(nd in n for nd in no_decay)],\n","              'weight_decay_rate': 0.01},\n","              {'params': [p for n, p in polarity_param_optimizer if any(nd in n for nd in no_decay)],\n","              'weight_decay_rate': 0.0}\n","          ]\n","      else:\n","          polarity_param_optimizer = list(polarity_model.classifier.named_parameters())\n","          polarity_optimizer_grouped_parameters = [{\"params\": [p for n, p in polarity_param_optimizer]}]\n","\n","      polarity_optimizer = AdamW(\n","          polarity_optimizer_grouped_parameters,\n","          lr=polarity_learning_rate,\n","          eps=eps\n","      )\n","      epochs = num_train_epochs\n","      max_grad_norm = 1.0\n","      total_steps = epochs * len(polarity_train_dataloader)\n","\n","      polarity_scheduler = get_linear_schedule_with_warmup(\n","          polarity_optimizer,\n","          num_warmup_steps=0,\n","          num_training_steps=total_steps\n","      )\n","\n","\n","      epoch_step = 0\n","      polarity_patience = 0\n","      for _ in trange(epochs, desc=\"Epoch\"):\n","          polarity_model.train()\n","          epoch_step += 1\n","          if polarity_patience == int(polarity_patience_ub*3/5):\n","              model_load_path = polarity_classification_model_path + 'saved_model_epoch_' + str(val_step) + '.pt'\n","              polarity_model.load_state_dict(torch.load(model_load_path, map_location=device))\n","              polarity_model.to(device)\n","              for param in polarity_model.xlm_roberta.parameters():\n","                  param.requires_grad = True\n","              polarity_model.train()\n","          if polarity_patience <= polarity_patience_ub:\n","              polarity_total_loss = 0\n","\n","              for step, batch in enumerate(polarity_train_dataloader):\n","                  batch = tuple(t.to(device) for t in batch)\n","                  b_input_ids, b_input_mask, b_labels = batch\n","\n","                  polarity_model.zero_grad()\n","\n","                  loss, _ = polarity_model(b_input_ids, b_input_mask, b_labels)\n","\n","                  loss.backward()\n","\n","                  polarity_total_loss += loss.item()\n","                  # print('batch_loss: ', loss.item())\n","\n","                  torch.nn.utils.clip_grad_norm_(parameters=polarity_model.parameters(), max_norm=max_grad_norm)\n","                  polarity_optimizer.step()\n","                  polarity_scheduler.step()\n","\n","              avg_train_loss = polarity_total_loss / len(polarity_train_dataloader)\n","              print(\"Polarity_Epoch: \", epoch_step)\n","              print(\"Average train loss: {}\".format(avg_train_loss))\n","\n","\n","              if do_eval:\n","                  polarity_model.eval()\n","\n","                  pred_list = []\n","                  label_list = []\n","                  loss_list = []\n","                  for batch in polarity_dev_dataloader:\n","                      batch = tuple(t.to(device) for t in batch)\n","                      b_input_ids, b_input_mask, b_labels = batch\n","\n","                      with torch.no_grad():\n","                          loss, logits = polarity_model(b_input_ids, b_input_mask, b_labels)\n","                          loss_list.append(loss.item())\n","                  print('validation error: ', np.mean(loss_list))\n","                  if np.mean(loss_list) < polarity_val_best_loss:\n","                      polarity_val_best_loss = np.mean(loss_list)\n","                      model_saved_path = polarity_classification_model_path + 'saved_model_epoch_' + str(val_step) + '.pt'\n","                      torch.save(polarity_model.state_dict(), model_saved_path)\n","                      print('\\npolarity_model best model updated.')\n","                      polarity_patience = 0\n","                  else:\n","                      polarity_patience += 1\n","\n","\n","\n","      print(\"training is done\")\n","\n","\n","      val_step += 1\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2K7iPMzFjdWO","executionInfo":{"status":"ok","timestamp":1668298785135,"user_tz":-540,"elapsed":57122928,"user":{"displayName":"박윤식","userId":"16877335343800304841"}},"outputId":"049dc7ce-2f5a-4f1a-c6b5-9e04e53ee45b"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_sentiment_analysis\n","category_extraction model would be saved at  /content/drive/MyDrive/게임/korean_ABSA_baseline-main/saved_model5/category_extraction\n","polarity model would be saved at  /content/drive/MyDrive/게임/korean_ABSA_baseline-main/saved_model5/polarity_classification\n","loading train data\n","\n","\n","======================= 1 step=========================\n","\n","\n","\n","\n","\n","\n","\n","\n","tokenizing train data\n","We have added 8 tokens\n","loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["end loading\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   0%|          | 0/100 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Entity_Property_Epoch:  1\n","Average train loss: 1.1323650358850381\n","validation error:  1.1188477569526725\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   1%|          | 1/100 [02:18<3:48:44, 138.63s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  2\n","Average train loss: 1.1204011902239286\n","validation error:  1.1014910223600747\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   2%|▏         | 2/100 [04:25<3:35:13, 131.77s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  3\n","Average train loss: 1.109383067996724\n","validation error:  1.094018396380898\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   3%|▎         | 3/100 [06:32<3:29:23, 129.52s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  4\n","Average train loss: 1.1022170638577171\n","validation error:  1.0883897988946287\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   4%|▍         | 4/100 [08:39<3:25:32, 128.46s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  5\n","Average train loss: 1.095961675807336\n","validation error:  1.0843991666407018\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   5%|▌         | 5/100 [10:46<3:22:27, 127.87s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  6\n","Average train loss: 1.1001270004860755\n","validation error:  1.0817276476980089\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   6%|▌         | 6/100 [12:52<3:19:45, 127.51s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  7\n","Average train loss: 1.0940297203030445\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   7%|▋         | 7/100 [14:55<3:15:17, 126.00s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0827128274457438\n","Entity_Property_Epoch:  8\n","Average train loss: 1.0883157841979096\n","validation error:  1.077848943797025\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   8%|▊         | 8/100 [17:02<3:13:34, 126.25s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  9\n","Average train loss: 1.0889289835844391\n","validation error:  1.0773404444847907\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   9%|▉         | 9/100 [19:09<3:11:45, 126.44s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  10\n","Average train loss: 1.0899276663213706\n","validation error:  1.0760566233754991\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  10%|█         | 10/100 [21:16<3:09:50, 126.56s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  11\n","Average train loss: 1.0883588807654088\n","validation error:  1.0755951454589416\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  11%|█         | 11/100 [23:23<3:07:50, 126.64s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  12\n","Average train loss: 1.0879004188078358\n","validation error:  1.07501127211364\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  12%|█▏        | 12/100 [25:29<3:05:48, 126.69s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  13\n","Average train loss: 1.0881291128210526\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  13%|█▎        | 13/100 [27:32<3:02:03, 125.55s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0752698645725116\n","Entity_Property_Epoch:  14\n","Average train loss: 1.0856037694037695\n","validation error:  1.074503088330889\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  14%|█▍        | 14/100 [29:39<3:00:30, 125.93s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  15\n","Average train loss: 1.0864789456600463\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  15%|█▌        | 15/100 [31:42<2:57:07, 125.03s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.089190568123664\n","Entity_Property_Epoch:  16\n","Average train loss: 1.086349083061587\n","validation error:  1.0742059208296395\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  16%|█▌        | 16/100 [33:49<2:55:46, 125.55s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  17\n","Average train loss: 1.0854596347926162\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  17%|█▋        | 17/100 [35:52<2:52:36, 124.78s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.080300514097814\n","Entity_Property_Epoch:  18\n","Average train loss: 1.083685141770408\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  18%|█▊        | 18/100 [37:55<2:49:44, 124.20s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0846841802130212\n","Entity_Property_Epoch:  19\n","Average train loss: 1.0842392701256254\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  19%|█▉        | 19/100 [39:57<2:47:06, 123.78s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0801202000437917\n","Entity_Property_Epoch:  20\n","Average train loss: 1.0819417718005726\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  20%|██        | 20/100 [42:00<2:44:39, 123.49s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0845828202220944\n","Entity_Property_Epoch:  21\n","Average train loss: 1.0871583089258634\n","validation error:  1.0735212810389645\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  21%|██        | 21/100 [44:07<2:43:55, 124.50s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  22\n","Average train loss: 1.0863952940503407\n","validation error:  1.0732975714690203\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  22%|██▏       | 22/100 [46:14<2:42:45, 125.20s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  23\n","Average train loss: 1.0835354134361856\n","validation error:  1.0731049784413584\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  23%|██▎       | 23/100 [48:21<2:41:19, 125.71s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  24\n","Average train loss: 1.0814860463142395\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  24%|██▍       | 24/100 [50:24<2:38:10, 124.88s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.073512325336883\n","Entity_Property_Epoch:  25\n","Average train loss: 1.0845166183942652\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  25%|██▌       | 25/100 [52:27<2:35:20, 124.27s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0735194307940823\n","Entity_Property_Epoch:  26\n","Average train loss: 1.0819458780263556\n","validation error:  1.0729315297586934\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  26%|██▌       | 26/100 [54:33<2:34:11, 125.02s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  27\n","Average train loss: 1.0832035206323767\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  27%|██▋       | 27/100 [56:36<2:31:20, 124.40s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.076406798579476\n","Entity_Property_Epoch:  28\n","Average train loss: 1.0806579169782897\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  28%|██▊       | 28/100 [58:39<2:28:43, 123.94s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0731686487064496\n","Entity_Property_Epoch:  29\n","Average train loss: 1.0818617393136654\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  29%|██▉       | 29/100 [1:00:42<2:26:16, 123.61s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0730392024233624\n","Entity_Property_Epoch:  30\n","Average train loss: 1.0814809672442807\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  30%|███       | 30/100 [1:02:45<2:23:56, 123.38s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0826421509255897\n","Entity_Property_Epoch:  31\n","Average train loss: 1.0809814788545162\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  31%|███       | 31/100 [1:04:48<2:21:42, 123.22s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.075984861467268\n","Entity_Property_Epoch:  32\n","Average train loss: 1.0831624042170747\n","validation error:  1.0721613022830936\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  32%|███▏      | 32/100 [1:06:55<2:20:50, 124.28s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  33\n","Average train loss: 1.0809945737540407\n","validation error:  1.071867004557923\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  33%|███▎      | 33/100 [1:09:01<2:19:37, 125.04s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  34\n","Average train loss: 1.0789419704874705\n","validation error:  1.071669442253513\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  34%|███▍      | 34/100 [1:11:08<2:18:08, 125.59s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  35\n","Average train loss: 1.0792922067516508\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  35%|███▌      | 35/100 [1:13:11<2:15:11, 124.80s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0747219545024258\n","Entity_Property_Epoch:  36\n","Average train loss: 1.0798963593263409\n","validation error:  1.0714414207251755\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  36%|███▌      | 36/100 [1:15:18<2:13:45, 125.39s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  37\n","Average train loss: 1.078301856304095\n","validation error:  1.0709044724911243\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  37%|███▋      | 37/100 [1:17:25<2:12:08, 125.84s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  38\n","Average train loss: 1.0796491109842994\n","validation error:  1.0704289049535365\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  38%|███▊      | 38/100 [1:19:32<2:10:23, 126.19s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  39\n","Average train loss: 1.0786215524681841\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  39%|███▉      | 39/100 [1:21:35<2:07:17, 125.21s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0737674553077539\n","Entity_Property_Epoch:  40\n","Average train loss: 1.0769928249617242\n","validation error:  1.0699181477506678\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  40%|████      | 40/100 [1:23:42<2:05:40, 125.68s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  41\n","Average train loss: 1.0748364487515603\n","validation error:  1.0693716506857973\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  41%|████      | 41/100 [1:25:48<2:03:55, 126.03s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  42\n","Average train loss: 1.0750437246894167\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  42%|████▏     | 42/100 [1:27:51<2:00:55, 125.09s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.072622888154917\n","Entity_Property_Epoch:  43\n","Average train loss: 1.0786588261123282\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  43%|████▎     | 43/100 [1:29:54<1:58:11, 124.42s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0722990361126987\n","Entity_Property_Epoch:  44\n","Average train loss: 1.0743608341694717\n","validation error:  1.0688899071900162\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  44%|████▍     | 44/100 [1:32:01<1:56:47, 125.14s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  45\n","Average train loss: 1.076427261733003\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  45%|████▌     | 45/100 [1:34:04<1:54:06, 124.48s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.084367082252369\n","Entity_Property_Epoch:  46\n","Average train loss: 1.0736429386482507\n","validation error:  1.0678073659643426\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  46%|████▌     | 46/100 [1:36:11<1:52:39, 125.17s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  47\n","Average train loss: 1.0756827913394922\n","validation error:  1.0677949765345434\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  47%|████▋     | 47/100 [1:38:18<1:51:01, 125.68s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  48\n","Average train loss: 1.074110587368112\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  48%|████▊     | 48/100 [1:40:21<1:48:12, 124.86s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0700139165758253\n","Entity_Property_Epoch:  49\n","Average train loss: 1.0703407216993912\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  49%|████▉     | 49/100 [1:42:23<1:45:37, 124.26s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0703900460596685\n","Entity_Property_Epoch:  50\n","Average train loss: 1.0741631303814048\n","validation error:  1.0668397020626734\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  50%|█████     | 50/100 [1:44:30<1:44:11, 125.03s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  51\n","Average train loss: 1.0720010375725155\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  51%|█████     | 51/100 [1:46:33<1:41:35, 124.39s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0820890477487257\n","Entity_Property_Epoch:  52\n","Average train loss: 1.0693192905198081\n","validation error:  1.0662170173404935\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  52%|█████▏    | 52/100 [1:48:40<1:40:04, 125.10s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  53\n","Average train loss: 1.068823645843982\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  53%|█████▎    | 53/100 [1:50:43<1:37:29, 124.45s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0753225713343053\n","Entity_Property_Epoch:  54\n","Average train loss: 1.071362985144181\n","validation error:  1.0654603063643395\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  54%|█████▍    | 54/100 [1:52:50<1:35:57, 125.16s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  55\n","Average train loss: 1.0689446177130635\n","validation error:  1.0650928587346644\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  55%|█████▌    | 55/100 [1:54:56<1:34:15, 125.67s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  56\n","Average train loss: 1.0679815270150692\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  56%|█████▌    | 56/100 [1:56:59<1:31:34, 124.87s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0674469883625324\n","Entity_Property_Epoch:  57\n","Average train loss: 1.0687951564998326\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  57%|█████▋    | 57/100 [1:59:02<1:29:04, 124.28s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.074086625676055\n","Entity_Property_Epoch:  58\n","Average train loss: 1.069547587727411\n","validation error:  1.0634507120072425\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  58%|█████▊    | 58/100 [2:01:09<1:27:32, 125.06s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  59\n","Average train loss: 1.0674127236610975\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  59%|█████▉    | 59/100 [2:03:12<1:25:01, 124.42s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0763957141996263\n","Entity_Property_Epoch:  60\n","Average train loss: 1.0672816180596243\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  60%|██████    | 60/100 [2:05:15<1:22:38, 123.96s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0692908963957033\n","Entity_Property_Epoch:  61\n","Average train loss: 1.064021434955731\n","validation error:  1.0631093403676173\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  61%|██████    | 61/100 [2:07:22<1:21:07, 124.81s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  62\n","Average train loss: 1.0665627306291214\n","validation error:  1.0623760798594335\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  62%|██████▏   | 62/100 [2:09:29<1:19:26, 125.43s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  63\n","Average train loss: 1.065415181154107\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  63%|██████▎   | 63/100 [2:11:32<1:16:53, 124.70s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0625197641499393\n","Entity_Property_Epoch:  64\n","Average train loss: 1.0669806509005373\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  64%|██████▍   | 64/100 [2:13:35<1:14:28, 124.13s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0715463103114309\n","Entity_Property_Epoch:  65\n","Average train loss: 1.0640245074756536\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  65%|██████▌   | 65/100 [2:15:37<1:12:10, 123.74s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0708717455813934\n","Entity_Property_Epoch:  66\n","Average train loss: 1.0650500064365473\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  66%|██████▌   | 66/100 [2:17:40<1:09:57, 123.46s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.081332173797634\n","Entity_Property_Epoch:  67\n","Average train loss: 1.062059581070248\n","validation error:  1.0611985555061927\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  67%|██████▋   | 67/100 [2:19:47<1:08:26, 124.45s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  68\n","Average train loss: 1.064131695168299\n","validation error:  1.0608260098037186\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  68%|██████▊   | 68/100 [2:21:54<1:06:45, 125.16s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  69\n","Average train loss: 1.0645999311353285\n","validation error:  1.0606800813774961\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  69%|██████▉   | 69/100 [2:24:01<1:04:56, 125.68s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  70\n","Average train loss: 1.0651626007628148\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  70%|███████   | 70/100 [2:26:04<1:02:25, 124.85s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.063210499453378\n","Entity_Property_Epoch:  71\n","Average train loss: 1.060055409824911\n","validation error:  1.0593247978420524\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  71%|███████   | 71/100 [2:28:10<1:00:37, 125.42s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  72\n","Average train loss: 1.061829576697626\n","validation error:  1.0590664235861984\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  72%|███████▏  | 72/100 [2:30:17<58:44, 125.88s/it]  "]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  73\n","Average train loss: 1.0612978101405193\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  73%|███████▎  | 73/100 [2:32:20<56:14, 125.00s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0623950091275303\n","Entity_Property_Epoch:  74\n","Average train loss: 1.058471953931718\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  74%|███████▍  | 74/100 [2:34:23<53:52, 124.34s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.075985446259692\n","Entity_Property_Epoch:  75\n","Average train loss: 1.0610782679543553\n","validation error:  1.0585847597022158\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  75%|███████▌  | 75/100 [2:36:30<52:06, 125.06s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  76\n","Average train loss: 1.0584647154242377\n","validation error:  1.058582010802689\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  76%|███████▌  | 76/100 [2:38:36<50:13, 125.57s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  77\n","Average train loss: 1.064663722351691\n","validation error:  1.0577976282659944\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  77%|███████▋  | 77/100 [2:40:43<48:16, 125.95s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  78\n","Average train loss: 1.0568902067224673\n","validation error:  1.0574203906776187\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  78%|███████▊  | 78/100 [2:42:50<46:16, 126.20s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  79\n","Average train loss: 1.0615227545082884\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  79%|███████▉  | 79/100 [2:44:53<43:49, 125.20s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.07283590973674\n","Entity_Property_Epoch:  80\n","Average train loss: 1.056689121182648\n","validation error:  1.0568596641500514\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  80%|████████  | 80/100 [2:47:00<41:53, 125.65s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  81\n","Average train loss: 1.0590180080050116\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  81%|████████  | 81/100 [2:49:03<39:31, 124.81s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0666604713126495\n","Entity_Property_Epoch:  82\n","Average train loss: 1.0592193504523728\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  82%|████████▏ | 82/100 [2:51:05<37:15, 124.20s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0626101985677971\n","Entity_Property_Epoch:  83\n","Average train loss: 1.0593218718031798\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  83%|████████▎ | 83/100 [2:53:08<35:04, 123.78s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.059601224385775\n","Entity_Property_Epoch:  84\n","Average train loss: 1.056503489692098\n","validation error:  1.0567107913377403\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  84%|████████▍ | 84/100 [2:55:15<33:14, 124.67s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  85\n","Average train loss: 1.0594519191341367\n","validation error:  1.0564897427192101\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  85%|████████▌ | 85/100 [2:57:22<31:19, 125.33s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  86\n","Average train loss: 1.0561161793388676\n","validation error:  1.055935291351972\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  86%|████████▌ | 86/100 [2:59:29<29:20, 125.77s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  87\n","Average train loss: 1.0571806714698175\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  87%|████████▋ | 87/100 [3:01:32<27:04, 124.93s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0686005979151159\n","Entity_Property_Epoch:  88\n","Average train loss: 1.0565522665089169\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  88%|████████▊ | 88/100 [3:03:34<24:51, 124.29s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.059675794172954\n","Entity_Property_Epoch:  89\n","Average train loss: 1.0583787357241492\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  89%|████████▉ | 89/100 [3:05:37<22:42, 123.84s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.1065327074977902\n","Entity_Property_Epoch:  90\n","Average train loss: 1.0570484559020594\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  90%|█████████ | 90/100 [3:07:40<20:35, 123.53s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0585890391489843\n","Entity_Property_Epoch:  91\n","Average train loss: 1.0577308643471797\n","validation error:  1.0556842905658108\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  91%|█████████ | 91/100 [3:09:47<18:40, 124.49s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  92\n","Average train loss: 1.0576394416640638\n","validation error:  1.0554433252427962\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  92%|█████████▏| 92/100 [3:11:53<16:41, 125.17s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  93\n","Average train loss: 1.05793150290454\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  93%|█████████▎| 93/100 [3:13:56<14:31, 124.49s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0709309571689658\n","Entity_Property_Epoch:  94\n","Average train loss: 1.0594354041431406\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  94%|█████████▍| 94/100 [3:15:59<12:23, 123.98s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0585481157669654\n","Entity_Property_Epoch:  95\n","Average train loss: 1.0565814506819042\n","validation error:  1.055362899403472\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  95%|█████████▌| 95/100 [3:18:06<10:23, 124.79s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  96\n","Average train loss: 1.053921439316654\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  96%|█████████▌| 96/100 [3:20:09<08:16, 124.21s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0753753918867845\n","Entity_Property_Epoch:  97\n","Average train loss: 1.0544525026646565\n","validation error:  1.0545661393162253\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  97%|█████████▋| 97/100 [3:22:15<06:14, 124.97s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  98\n","Average train loss: 1.0544499433312977\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  98%|█████████▊| 98/100 [3:24:18<04:08, 124.35s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0551888252888526\n","Entity_Property_Epoch:  99\n","Average train loss: 1.0567161236580311\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  99%|█████████▉| 99/100 [3:26:21<02:03, 123.88s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0653274780386812\n","Entity_Property_Epoch:  100\n","Average train loss: 1.0558372834445302\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 100/100 [3:28:24<00:00, 125.04s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0755620011082896\n","\n","\n","======================= 2 step=========================\n","\n","\n","\n","\n","\n","\n","\n","\n","tokenizing train data\n","We have added 8 tokens\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["end loading\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   0%|          | 0/100 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Entity_Property_Epoch:  1\n","Average train loss: 1.1343479137638541\n","validation error:  1.122476376436807\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   1%|          | 1/100 [02:17<3:46:40, 137.38s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  2\n","Average train loss: 1.1193792054229965\n","validation error:  1.110019501272615\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   2%|▏         | 2/100 [04:26<3:36:23, 132.48s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  3\n","Average train loss: 1.1094325192154815\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   3%|▎         | 3/100 [06:29<3:27:09, 128.13s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.114823713586047\n","Entity_Property_Epoch:  4\n","Average train loss: 1.1030904645450506\n","validation error:  1.0958867552397134\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   4%|▍         | 4/100 [08:35<3:23:53, 127.43s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  5\n","Average train loss: 1.0991997396170778\n","validation error:  1.0916101903348536\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   5%|▌         | 5/100 [10:42<3:21:17, 127.13s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  6\n","Average train loss: 1.093714967029585\n","validation error:  1.088456865374025\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   6%|▌         | 6/100 [12:48<3:18:50, 126.92s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  7\n","Average train loss: 1.0893809188857857\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   7%|▋         | 7/100 [14:51<3:14:43, 125.63s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0891306754592416\n","Entity_Property_Epoch:  8\n","Average train loss: 1.0894829010712033\n","validation error:  1.0846393750264094\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   8%|▊         | 8/100 [16:58<3:13:01, 125.89s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  9\n","Average train loss: 1.0866687354387843\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   9%|▉         | 9/100 [19:01<3:09:34, 125.00s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.086733269524741\n","Entity_Property_Epoch:  10\n","Average train loss: 1.0872615676353603\n","validation error:  1.0830599394711582\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  10%|█         | 10/100 [21:07<3:08:16, 125.52s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  11\n","Average train loss: 1.0848805808015365\n","validation error:  1.083029872887618\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  11%|█         | 11/100 [23:14<3:06:45, 125.91s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  12\n","Average train loss: 1.0860100030270528\n","validation error:  1.0829005849944962\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  12%|█▏        | 12/100 [25:21<3:05:10, 126.25s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  13\n","Average train loss: 1.08395863186915\n","validation error:  1.082432087901589\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  13%|█▎        | 13/100 [27:28<3:03:18, 126.42s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  14\n","Average train loss: 1.0840118334666287\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  14%|█▍        | 14/100 [29:31<2:59:50, 125.47s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0926052015144507\n","Entity_Property_Epoch:  15\n","Average train loss: 1.083887600940644\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  15%|█▌        | 15/100 [31:35<2:56:51, 124.84s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0828821013023804\n","Entity_Property_Epoch:  16\n","Average train loss: 1.0837651162239705\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  16%|█▌        | 16/100 [33:38<2:54:16, 124.49s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.092026834304516\n","Entity_Property_Epoch:  17\n","Average train loss: 1.0827083468227687\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  17%|█▋        | 17/100 [35:42<2:51:41, 124.12s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0830714148241323\n","Entity_Property_Epoch:  18\n","Average train loss: 1.0835507261732131\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  18%|█▊        | 18/100 [37:45<2:49:15, 123.85s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0828788814011154\n","Entity_Property_Epoch:  19\n","Average train loss: 1.08226478445509\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  19%|█▉        | 19/100 [39:48<2:46:56, 123.67s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0863651479040826\n","Entity_Property_Epoch:  20\n","Average train loss: 0.9300084826921118\n","validation error:  0.7876463988861004\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  20%|██        | 20/100 [43:04<3:13:35, 145.19s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  21\n","Average train loss: 0.7360747483786464\n","validation error:  0.7194262303255655\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  21%|██        | 21/100 [46:18<3:30:32, 159.91s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  22\n","Average train loss: 0.6733465575480503\n","validation error:  0.6959092892133273\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  22%|██▏       | 22/100 [49:32<3:41:15, 170.20s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  23\n","Average train loss: 0.6249351975997429\n","validation error:  0.6844921553885186\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  23%|██▎       | 23/100 [52:46<3:47:39, 177.39s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  24\n","Average train loss: 0.5901751895885267\n","validation error:  0.6837832127417718\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  24%|██▍       | 24/100 [56:00<3:51:03, 182.41s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  25\n","Average train loss: 0.5597502732214065\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  25%|██▌       | 25/100 [59:11<3:51:04, 184.86s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.687601525258351\n","Entity_Property_Epoch:  26\n","Average train loss: 0.5365600753019062\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  26%|██▌       | 26/100 [1:02:21<3:50:03, 186.53s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6943708460230927\n","Entity_Property_Epoch:  27\n","Average train loss: 0.5114008904236691\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  27%|██▋       | 27/100 [1:05:32<3:48:21, 187.69s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.703131767836484\n","Entity_Property_Epoch:  28\n","Average train loss: 0.49448346463154824\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  28%|██▊       | 28/100 [1:08:42<3:46:15, 188.55s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6997049432117622\n","Entity_Property_Epoch:  29\n","Average train loss: 0.48242588186724955\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  29%|██▉       | 29/100 [1:11:53<3:43:44, 189.08s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.695468176703353\n","Entity_Property_Epoch:  30\n","Average train loss: 0.4609930716939467\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  30%|███       | 30/100 [1:15:03<3:41:03, 189.48s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6958809667950744\n","Entity_Property_Epoch:  31\n","Average train loss: 0.5607223377705458\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  31%|███       | 31/100 [1:18:15<3:38:41, 190.17s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6994886277438878\n","Entity_Property_Epoch:  32\n","Average train loss: 0.5341322681815847\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  32%|███▏      | 32/100 [1:21:26<3:35:44, 190.36s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6983817878302995\n","Entity_Property_Epoch:  33\n","Average train loss: 0.5175721442133764\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  33%|███▎      | 33/100 [1:24:36<3:32:41, 190.47s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6969142662478494\n","Entity_Property_Epoch:  34\n","Average train loss: 0.49824678798342004\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  34%|███▍      | 34/100 [1:27:47<3:29:37, 190.57s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.7063396454274238\n","Entity_Property_Epoch:  35\n","Average train loss: 0.4810904138746077\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 100/100 [1:30:58<00:00, 54.58s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.7133623305317405\n","\n","\n","======================= 3 step=========================\n","\n","\n","\n","\n","\n","\n","\n","\n","tokenizing train data\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["We have added 8 tokens\n","loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["end loading\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   0%|          | 0/100 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Entity_Property_Epoch:  1\n","Average train loss: 1.1325880643144015\n","validation error:  1.1147292681507297\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   1%|          | 1/100 [02:16<3:45:56, 136.94s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  2\n","Average train loss: 1.1174682176594994\n","validation error:  1.104253034491639\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   2%|▏         | 2/100 [04:24<3:34:56, 131.60s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  3\n","Average train loss: 1.1048726088552359\n","validation error:  1.0933308159554755\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   3%|▎         | 3/100 [06:32<3:29:39, 129.69s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  4\n","Average train loss: 1.099871934507769\n","validation error:  1.0879552518571174\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   4%|▍         | 4/100 [08:39<3:26:00, 128.75s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  5\n","Average train loss: 1.0956807251764307\n","validation error:  1.0841755775304942\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   5%|▌         | 5/100 [10:46<3:23:04, 128.26s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  6\n","Average train loss: 1.0908897824991357\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   6%|▌         | 6/100 [12:50<3:18:31, 126.72s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0927309323024084\n","Entity_Property_Epoch:  7\n","Average train loss: 1.0875131191394452\n","validation error:  1.0804080029467602\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   7%|▋         | 7/100 [14:57<3:16:39, 126.88s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  8\n","Average train loss: 1.0880333543452312\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   8%|▊         | 8/100 [17:01<3:13:00, 125.88s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0913605168982818\n","Entity_Property_Epoch:  9\n","Average train loss: 1.0886613943455299\n","validation error:  1.0791341670743235\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   9%|▉         | 9/100 [19:08<3:11:16, 126.11s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  10\n","Average train loss: 1.083844800929822\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  10%|█         | 10/100 [21:11<3:07:46, 125.18s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0951798328986535\n","Entity_Property_Epoch:  11\n","Average train loss: 1.0862699827745634\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  11%|█         | 11/100 [23:14<3:04:42, 124.52s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0818685872571452\n","Entity_Property_Epoch:  12\n","Average train loss: 1.0864088213716114\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  12%|█▏        | 12/100 [25:17<3:01:57, 124.06s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0917559691242404\n","Entity_Property_Epoch:  13\n","Average train loss: 1.0846033083743076\n","validation error:  1.078555739009297\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  13%|█▎        | 13/100 [27:23<3:00:59, 124.82s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  14\n","Average train loss: 1.0838345843375463\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  14%|█▍        | 14/100 [29:27<2:58:12, 124.33s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0787218871650162\n","Entity_Property_Epoch:  15\n","Average train loss: 1.0845169790599802\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  15%|█▌        | 15/100 [31:30<2:55:37, 123.98s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.079094070654649\n","Entity_Property_Epoch:  16\n","Average train loss: 1.085738123615513\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  16%|█▌        | 16/100 [33:33<2:53:11, 123.71s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.082036807403698\n","Entity_Property_Epoch:  17\n","Average train loss: 1.0830755979608357\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  17%|█▋        | 17/100 [35:36<2:50:53, 123.54s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0789924630751977\n","Entity_Property_Epoch:  18\n","Average train loss: 1.0831333263687175\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  18%|█▊        | 18/100 [37:39<2:48:39, 123.41s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0795027038434168\n","Entity_Property_Epoch:  19\n","Average train loss: 1.0855710435206944\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  19%|█▉        | 19/100 [39:42<2:46:29, 123.33s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0796669454841348\n","Entity_Property_Epoch:  20\n","Average train loss: 0.911279445163814\n","validation error:  0.7459760041503639\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  20%|██        | 20/100 [42:57<3:13:10, 144.88s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  21\n","Average train loss: 0.7182133866634436\n","validation error:  0.7041132635586745\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  21%|██        | 21/100 [46:11<3:30:03, 159.54s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  22\n","Average train loss: 0.6550780204771273\n","validation error:  0.6629489812400792\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  22%|██▏       | 22/100 [49:25<3:40:47, 169.84s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  23\n","Average train loss: 0.6134618487215628\n","validation error:  0.6623996975538614\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  23%|██▎       | 23/100 [52:39<3:47:13, 177.06s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  24\n","Average train loss: 0.5804897863647012\n","validation error:  0.6454698574709725\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  24%|██▍       | 24/100 [55:52<3:50:32, 182.01s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  25\n","Average train loss: 0.5482303965280262\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  25%|██▌       | 25/100 [59:02<3:50:33, 184.44s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6570150998088863\n","Entity_Property_Epoch:  26\n","Average train loss: 0.5258747877157007\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  26%|██▌       | 26/100 [1:02:12<3:49:30, 186.09s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6542258360585966\n","Entity_Property_Epoch:  27\n","Average train loss: 0.5009596196964042\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  27%|██▋       | 27/100 [1:05:22<3:47:48, 187.24s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6529170372686186\n","Entity_Property_Epoch:  28\n","Average train loss: 0.4835216787975995\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  28%|██▊       | 28/100 [1:08:32<3:45:40, 188.06s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6628538457663743\n","Entity_Property_Epoch:  29\n","Average train loss: 0.4705002337746545\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  29%|██▉       | 29/100 [1:11:42<3:43:12, 188.63s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6667766514774802\n","Entity_Property_Epoch:  30\n","Average train loss: 0.457090236809635\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  30%|███       | 30/100 [1:14:52<3:40:31, 189.03s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6766072153211473\n","Entity_Property_Epoch:  31\n","Average train loss: 0.5483946170140653\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  31%|███       | 31/100 [1:18:04<3:38:10, 189.71s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6504510899523755\n","Entity_Property_Epoch:  32\n","Average train loss: 0.5267461693349748\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  32%|███▏      | 32/100 [1:21:13<3:35:05, 189.78s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6464978627391629\n","Entity_Property_Epoch:  33\n","Average train loss: 0.5054708469940614\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  33%|███▎      | 33/100 [1:24:23<3:31:58, 189.83s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6506806907953916\n","Entity_Property_Epoch:  34\n","Average train loss: 0.48632157498378115\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  34%|███▍      | 34/100 [1:27:33<3:28:50, 189.85s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6656874889260406\n","Entity_Property_Epoch:  35\n","Average train loss: 0.475324149291\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 100/100 [1:30:43<00:00, 54.44s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6525627310042614\n","\n","\n","======================= 4 step=========================\n","\n","\n","\n","\n","\n","\n","\n","\n","tokenizing train data\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["We have added 8 tokens\n","loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["end loading\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   0%|          | 0/100 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Entity_Property_Epoch:  1\n","Average train loss: 1.1225010638496788\n","validation error:  1.1209292636884676\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   1%|          | 1/100 [02:20<3:52:31, 140.92s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  2\n","Average train loss: 1.1117721940595362\n","validation error:  1.104248561225571\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   2%|▏         | 2/100 [04:27<3:36:29, 132.55s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  3\n","Average train loss: 1.1058201931272953\n","validation error:  1.0973480064552148\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   3%|▎         | 3/100 [06:34<3:30:05, 129.96s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  4\n","Average train loss: 1.0984174879447857\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   4%|▍         | 4/100 [08:37<3:23:36, 127.26s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.1042598423424301\n","Entity_Property_Epoch:  5\n","Average train loss: 1.0963570164460918\n","validation error:  1.0868099040084787\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   5%|▌         | 5/100 [10:44<3:21:08, 127.03s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  6\n","Average train loss: 1.0920674989428796\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   6%|▌         | 6/100 [12:47<3:16:55, 125.69s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0916521695110348\n","Entity_Property_Epoch:  7\n","Average train loss: 1.0907132972313356\n","validation error:  1.0823215504626293\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   7%|▋         | 7/100 [14:53<3:15:15, 125.98s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  8\n","Average train loss: 1.0875485890359995\n","validation error:  1.0813911244585797\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   8%|▊         | 8/100 [17:00<3:13:31, 126.21s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  9\n","Average train loss: 1.0874035230629893\n","validation error:  1.0811343234735769\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   9%|▉         | 9/100 [19:07<3:11:38, 126.36s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  10\n","Average train loss: 1.0875125130366776\n","validation error:  1.0800153058725637\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  10%|█         | 10/100 [21:14<3:09:46, 126.51s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  11\n","Average train loss: 1.0875049691208636\n","validation error:  1.0796802289836056\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  11%|█         | 11/100 [23:20<3:07:44, 126.57s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  12\n","Average train loss: 1.0877353519672668\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  12%|█▏        | 12/100 [25:24<3:04:08, 125.56s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0826625757284098\n","Entity_Property_Epoch:  13\n","Average train loss: 1.0850617380678549\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  13%|█▎        | 13/100 [27:27<3:01:00, 124.83s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0799841918311752\n","Entity_Property_Epoch:  14\n","Average train loss: 1.0851557906356972\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  14%|█▍        | 14/100 [29:30<2:58:25, 124.48s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.079862782171556\n","Entity_Property_Epoch:  15\n","Average train loss: 1.08672875626854\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  15%|█▌        | 15/100 [31:34<2:56:00, 124.24s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0797050065927571\n","Entity_Property_Epoch:  16\n","Average train loss: 1.0878449227981701\n","validation error:  1.0796169150959363\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  16%|█▌        | 16/100 [33:42<2:55:17, 125.20s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  17\n","Average train loss: 1.0858706481008413\n","validation error:  1.079236594947068\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  17%|█▋        | 17/100 [35:49<2:54:06, 125.86s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  18\n","Average train loss: 1.0835594020535113\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  18%|█▊        | 18/100 [37:53<2:51:10, 125.25s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0997571361648453\n","Entity_Property_Epoch:  19\n","Average train loss: 1.0862845300790087\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  19%|█▉        | 19/100 [39:56<2:48:26, 124.77s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0954443520599313\n","Entity_Property_Epoch:  20\n","Average train loss: 1.0841589766981732\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  20%|██        | 20/100 [42:00<2:45:44, 124.31s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0793086882237788\n","Entity_Property_Epoch:  21\n","Average train loss: 1.086895669281797\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  21%|██        | 21/100 [44:03<2:43:13, 123.96s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0798370112905968\n","Entity_Property_Epoch:  22\n","Average train loss: 1.0885110197880146\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  22%|██▏       | 22/100 [46:06<2:40:54, 123.78s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0986621596596458\n","Entity_Property_Epoch:  23\n","Average train loss: 1.0849009280883575\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  23%|██▎       | 23/100 [48:09<2:38:36, 123.59s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0829283194942074\n","Entity_Property_Epoch:  24\n","Average train loss: 0.9128858417220191\n","validation error:  0.7681672539744344\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  24%|██▍       | 24/100 [51:25<3:03:54, 145.20s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  25\n","Average train loss: 0.7329574012588742\n","validation error:  0.7067772129198888\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  25%|██▌       | 25/100 [54:39<3:19:49, 159.87s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  26\n","Average train loss: 0.665814691352509\n","validation error:  0.6881230340137349\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  26%|██▌       | 26/100 [57:53<3:29:49, 170.13s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  27\n","Average train loss: 0.6234112130527127\n","validation error:  0.6840156985746397\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  27%|██▋       | 27/100 [1:01:07<3:35:42, 177.30s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  28\n","Average train loss: 0.585578840782437\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  28%|██▊       | 28/100 [1:04:18<3:37:31, 181.27s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6908615369063157\n","Entity_Property_Epoch:  29\n","Average train loss: 0.5540627407168671\n","validation error:  0.6777966520586214\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  29%|██▉       | 29/100 [1:07:31<3:38:57, 185.04s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  30\n","Average train loss: 0.5311654826040217\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  30%|███       | 30/100 [1:10:42<3:37:41, 186.60s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.69298632995232\n","Entity_Property_Epoch:  31\n","Average train loss: 0.5064868382808404\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  31%|███       | 31/100 [1:13:52<3:35:47, 187.65s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.7133224785744727\n","Entity_Property_Epoch:  32\n","Average train loss: 0.4909033475735066\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  32%|███▏      | 32/100 [1:17:02<3:33:30, 188.38s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.696211850934929\n","Entity_Property_Epoch:  33\n","Average train loss: 0.47375644452752047\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  33%|███▎      | 33/100 [1:20:13<3:31:14, 189.17s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6924653861906145\n","Entity_Property_Epoch:  34\n","Average train loss: 0.46208283556576146\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  34%|███▍      | 34/100 [1:23:23<3:28:31, 189.56s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.7000185615949698\n","Entity_Property_Epoch:  35\n","Average train loss: 0.4531214755218352\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  35%|███▌      | 35/100 [1:26:34<3:25:46, 189.95s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6895571957518171\n","Entity_Property_Epoch:  36\n","Average train loss: 0.5290410755912532\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  36%|███▌      | 36/100 [1:29:47<3:23:25, 190.71s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.7042928306789665\n","Entity_Property_Epoch:  37\n","Average train loss: 0.511628276853444\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  37%|███▋      | 37/100 [1:32:58<3:20:20, 190.81s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6877719355629874\n","Entity_Property_Epoch:  38\n","Average train loss: 0.49572025598247776\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  38%|███▊      | 38/100 [1:36:09<3:17:18, 190.94s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6934648775137388\n","Entity_Property_Epoch:  39\n","Average train loss: 0.47684386665875544\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  39%|███▉      | 39/100 [1:39:20<3:14:14, 191.05s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.7003159110362713\n","Entity_Property_Epoch:  40\n","Average train loss: 0.46589831837660817\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 100/100 [1:42:31<00:00, 61.52s/it]  "]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6969140663847223\n","\n","\n","======================= 5 step=========================\n","\n","\n","\n","\n","\n","\n","\n","\n","tokenizing train data\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["We have added 8 tokens\n","loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["end loading\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   0%|          | 0/100 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Entity_Property_Epoch:  1\n","Average train loss: 1.1190290469905404\n","validation error:  1.113040051409896\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   1%|          | 1/100 [02:16<3:44:43, 136.19s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  2\n","Average train loss: 1.1048363187401073\n","validation error:  1.102893207694443\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   2%|▏         | 2/100 [04:22<3:33:21, 130.63s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  3\n","Average train loss: 1.0945165805741228\n","validation error:  1.0966842304652846\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   3%|▎         | 3/100 [06:29<3:28:17, 128.84s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  4\n","Average train loss: 1.0907867366484054\n","validation error:  1.0934317141351566\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   4%|▍         | 4/100 [08:36<3:24:45, 127.98s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  5\n","Average train loss: 1.0883196260262877\n","validation error:  1.092033608278758\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   5%|▌         | 5/100 [10:42<3:21:52, 127.50s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  6\n","Average train loss: 1.0849712974995847\n","validation error:  1.0917046674540345\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   6%|▌         | 6/100 [12:49<3:19:20, 127.24s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  7\n","Average train loss: 1.0833094027842705\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   7%|▋         | 7/100 [14:52<3:15:07, 125.89s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.091884733085901\n","Entity_Property_Epoch:  8\n","Average train loss: 1.0838664185602762\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   8%|▊         | 8/100 [16:55<3:11:39, 124.99s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.092608175647091\n","Entity_Property_Epoch:  9\n","Average train loss: 1.0854210204106014\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   9%|▉         | 9/100 [18:58<3:08:39, 124.39s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0934294978497734\n","Entity_Property_Epoch:  10\n","Average train loss: 1.0836497886738166\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  10%|█         | 10/100 [21:02<3:05:58, 123.99s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0943819607647371\n","Entity_Property_Epoch:  11\n","Average train loss: 1.0831296163200284\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  11%|█         | 11/100 [23:05<3:03:28, 123.70s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0955108987613462\n","Entity_Property_Epoch:  12\n","Average train loss: 1.0859112480822264\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  12%|█▏        | 12/100 [25:08<3:01:08, 123.50s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  1.0965170364984325\n","Entity_Property_Epoch:  13\n","Average train loss: 0.9251914990702497\n","validation error:  0.7643417105288572\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  13%|█▎        | 13/100 [28:23<3:30:27, 145.14s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  14\n","Average train loss: 0.7171108243440283\n","validation error:  0.6951885538201936\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  14%|█▍        | 14/100 [31:37<3:49:11, 159.90s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  15\n","Average train loss: 0.6528953184980919\n","validation error:  0.6777387414599808\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  15%|█▌        | 15/100 [34:51<4:01:07, 170.21s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  16\n","Average train loss: 0.607243977238298\n","validation error:  0.659698507315676\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  16%|█▌        | 16/100 [38:06<4:08:50, 177.75s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  17\n","Average train loss: 0.5689301956412244\n","validation error:  0.6422648887399217\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  17%|█▋        | 17/100 [41:21<4:13:11, 183.03s/it]"]},{"output_type":"stream","name":"stdout","text":["entity_property_model best model updated.\n","Entity_Property_Epoch:  18\n","Average train loss: 0.5378307186865848\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  18%|█▊        | 18/100 [44:32<4:13:23, 185.41s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6543290927796297\n","Entity_Property_Epoch:  19\n","Average train loss: 0.5156879650268488\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  19%|█▉        | 19/100 [47:43<4:12:24, 186.96s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.665290085572592\n","Entity_Property_Epoch:  20\n","Average train loss: 0.4870288593593088\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  20%|██        | 20/100 [50:54<4:10:49, 188.12s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.642719256416173\n","Entity_Property_Epoch:  21\n","Average train loss: 0.4696145384508612\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  21%|██        | 21/100 [54:04<4:08:44, 188.92s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6575226175113463\n","Entity_Property_Epoch:  22\n","Average train loss: 0.4562486190158998\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  22%|██▏       | 22/100 [57:15<4:06:20, 189.49s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.668445906588729\n","Entity_Property_Epoch:  23\n","Average train loss: 0.44363747801638237\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  23%|██▎       | 23/100 [1:00:26<4:03:43, 189.92s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6757594785639938\n","Entity_Property_Epoch:  24\n","Average train loss: 0.540531726262691\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  24%|██▍       | 24/100 [1:03:38<4:01:25, 190.60s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6485210541688221\n","Entity_Property_Epoch:  25\n","Average train loss: 0.5108788402093106\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  25%|██▌       | 25/100 [1:06:49<3:58:21, 190.69s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.656988359043296\n","Entity_Property_Epoch:  26\n","Average train loss: 0.4910312307006655\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  26%|██▌       | 26/100 [1:10:00<3:55:11, 190.69s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6639436984985647\n","Entity_Property_Epoch:  27\n","Average train loss: 0.47042080702387806\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  27%|██▋       | 27/100 [1:13:11<3:51:59, 190.68s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6637053114007896\n","Entity_Property_Epoch:  28\n","Average train loss: 0.456926733622023\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 100/100 [1:16:21<00:00, 45.82s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.652910052470758\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","======================= 1 step=========================\n","\n","\n","\n","\n","\n","\n","\n","\n","tokenizing train data\n","We have added 8 tokens\n","loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["end loading\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   0%|          | 0/100 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Polarity_Epoch:  1\n","Average train loss: 0.9907542188179317\n","validation error:  0.7357645783769456\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   1%|          | 1/100 [02:15<3:43:40, 135.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  2\n","Average train loss: 0.6324937645535555\n","validation error:  0.5352380379642311\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   2%|▏         | 2/100 [04:30<3:41:17, 135.48s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  3\n","Average train loss: 0.5139433752335547\n","validation error:  0.508272660994216\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   3%|▎         | 3/100 [06:46<3:39:01, 135.48s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  4\n","Average train loss: 0.49003090944343014\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   4%|▍         | 4/100 [08:58<3:34:27, 134.04s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5230857530412706\n","Polarity_Epoch:  5\n","Average train loss: 0.5044252638428278\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   5%|▌         | 5/100 [11:10<3:30:55, 133.22s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5433271010896485\n","Polarity_Epoch:  6\n","Average train loss: 0.5204798458648726\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   6%|▌         | 6/100 [13:21<3:27:54, 132.71s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5318022573023642\n","Polarity_Epoch:  7\n","Average train loss: 0.5391946638244616\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   7%|▋         | 7/100 [15:33<3:25:12, 132.39s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.54819515068084\n","Polarity_Epoch:  8\n","Average train loss: 0.5646777076062506\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   8%|▊         | 8/100 [17:45<3:22:43, 132.21s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5558472867859038\n","Polarity_Epoch:  9\n","Average train loss: 0.5596691710363664\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   9%|▉         | 9/100 [19:57<3:20:17, 132.06s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.563520134059026\n","Polarity_Epoch:  10\n","Average train loss: 0.5002446473287098\n","validation error:  0.47918625957773703\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  10%|█         | 10/100 [23:25<3:53:36, 155.74s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  11\n","Average train loss: 0.37940254009807445\n","validation error:  0.3761837209917997\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  11%|█         | 11/100 [26:53<4:14:31, 171.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  12\n","Average train loss: 0.3265704108747747\n","validation error:  0.3555761579497668\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  12%|█▏        | 12/100 [30:20<4:27:41, 182.52s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  13\n","Average train loss: 0.257348923339877\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  13%|█▎        | 13/100 [33:44<4:34:05, 189.03s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.3687439024154293\n","Polarity_Epoch:  14\n","Average train loss: 0.2095595109941704\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  14%|█▍        | 14/100 [37:08<4:37:21, 193.50s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4004293169556676\n","Polarity_Epoch:  15\n","Average train loss: 0.19258173510175328\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  15%|█▌        | 15/100 [40:32<4:38:37, 196.68s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.38481760194132986\n","Polarity_Epoch:  16\n","Average train loss: 0.15058875193112883\n","validation error:  0.34519593057369713\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  16%|█▌        | 16/100 [44:00<4:39:59, 199.99s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  17\n","Average train loss: 0.14728585120186527\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  17%|█▋        | 17/100 [47:25<4:38:35, 201.40s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.35899570179907114\n","Polarity_Epoch:  18\n","Average train loss: 0.11828573354426619\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  18%|█▊        | 18/100 [50:49<4:36:18, 202.17s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.35029165769044895\n","Polarity_Epoch:  19\n","Average train loss: 0.1007555251549593\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  19%|█▉        | 19/100 [54:13<4:33:40, 202.73s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.42374561723983406\n","Polarity_Epoch:  20\n","Average train loss: 0.07950983778994121\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  20%|██        | 20/100 [57:37<4:30:51, 203.14s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4015358472426765\n","Polarity_Epoch:  21\n","Average train loss: 0.07279028962037491\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  21%|██        | 21/100 [1:01:01<4:27:50, 203.43s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.35551386215650527\n","Polarity_Epoch:  22\n","Average train loss: 0.06286987850873782\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  22%|██▏       | 22/100 [1:04:25<4:24:41, 203.61s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4475003449172762\n","Polarity_Epoch:  23\n","Average train loss: 0.1485086619557296\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  23%|██▎       | 23/100 [1:07:50<4:21:56, 204.10s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.41518853648908827\n","Polarity_Epoch:  24\n","Average train loss: 0.11404731378956333\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  24%|██▍       | 24/100 [1:11:14<4:18:31, 204.09s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.38844282096742017\n","Polarity_Epoch:  25\n","Average train loss: 0.09483871753793974\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  25%|██▌       | 25/100 [1:14:38<4:15:07, 204.10s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4049409168502806\n","Polarity_Epoch:  26\n","Average train loss: 0.10274170679063192\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  26%|██▌       | 26/100 [1:18:02<4:11:43, 204.10s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.36732671827715085\n","Polarity_Epoch:  27\n","Average train loss: 0.07219458993200109\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 100/100 [1:21:27<00:00, 48.87s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.3865009087297183\n","training is done\n","\n","\n","======================= 2 step=========================\n","\n","\n","\n","\n","\n","\n","\n","\n","tokenizing train data\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["We have added 8 tokens\n","loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["end loading\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   0%|          | 0/100 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Polarity_Epoch:  1\n","Average train loss: 0.705254014434391\n","validation error:  0.56711261393198\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   1%|          | 1/100 [02:15<3:43:41, 135.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  2\n","Average train loss: 0.5400702167841557\n","validation error:  0.5045091768884971\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   2%|▏         | 2/100 [04:31<3:41:26, 135.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  3\n","Average train loss: 0.5045217230523887\n","validation error:  0.48574885725975037\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   3%|▎         | 3/100 [06:46<3:39:14, 135.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  4\n","Average train loss: 0.5205619056451771\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   4%|▍         | 4/100 [08:58<3:34:42, 134.19s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5435447139677658\n","Polarity_Epoch:  5\n","Average train loss: 0.5356328650561505\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   5%|▌         | 5/100 [11:10<3:31:09, 133.37s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5720363986842772\n","Polarity_Epoch:  6\n","Average train loss: 0.5403735485283265\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   6%|▌         | 6/100 [13:22<3:28:10, 132.87s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5590858695407709\n","Polarity_Epoch:  7\n","Average train loss: 0.5496111981092805\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   7%|▋         | 7/100 [15:34<3:25:27, 132.55s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5736360319591816\n","Polarity_Epoch:  8\n","Average train loss: 0.5682101904010204\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   8%|▊         | 8/100 [17:46<3:22:55, 132.35s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5335363539702752\n","Polarity_Epoch:  9\n","Average train loss: 0.5889366861083545\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   9%|▉         | 9/100 [19:58<3:20:31, 132.21s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.599289071301814\n","Polarity_Epoch:  10\n","Average train loss: 0.5190896195861953\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  10%|█         | 10/100 [23:23<3:52:04, 154.72s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5394094891456607\n","Polarity_Epoch:  11\n","Average train loss: 0.3675596683108444\n","validation error:  0.39069358552836514\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  11%|█         | 11/100 [26:50<4:13:24, 170.83s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  12\n","Average train loss: 0.3256046462078015\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  12%|█▏        | 12/100 [30:14<4:25:20, 180.92s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.43048074387403484\n","Polarity_Epoch:  13\n","Average train loss: 0.23665449134454034\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  13%|█▎        | 13/100 [33:38<4:32:20, 187.82s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.415349729042622\n","Polarity_Epoch:  14\n","Average train loss: 0.19330925257772355\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  14%|█▍        | 14/100 [37:02<4:36:06, 192.64s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4159028208236289\n","Polarity_Epoch:  15\n","Average train loss: 0.11972157952473744\n","validation error:  0.36800798896115783\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  15%|█▌        | 15/100 [40:29<4:39:15, 197.12s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  16\n","Average train loss: 0.0899299651347591\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  16%|█▌        | 16/100 [43:53<4:38:48, 199.15s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.41615045128475414\n","Polarity_Epoch:  17\n","Average train loss: 0.08117951393145822\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  17%|█▋        | 17/100 [47:17<4:37:18, 200.47s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4842506951707251\n","Polarity_Epoch:  18\n","Average train loss: 0.059375750939484294\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  18%|█▊        | 18/100 [50:40<4:35:16, 201.43s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.3766105324699501\n","Polarity_Epoch:  19\n","Average train loss: 0.057787946597703636\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  19%|█▉        | 19/100 [54:04<4:32:49, 202.09s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4046936769622798\n","Polarity_Epoch:  20\n","Average train loss: 0.061354877144606836\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  20%|██        | 20/100 [57:28<4:30:08, 202.61s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4235430741865261\n","Polarity_Epoch:  21\n","Average train loss: 0.053866972926985716\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  21%|██        | 21/100 [1:00:52<4:27:30, 203.17s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4180878859828987\n","Polarity_Epoch:  22\n","Average train loss: 0.12166739324732732\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  22%|██▏       | 22/100 [1:04:18<4:25:06, 203.93s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.49883882160864623\n","Polarity_Epoch:  23\n","Average train loss: 0.08082402429672104\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  23%|██▎       | 23/100 [1:07:42<4:21:51, 204.05s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.39594139548907287\n","Polarity_Epoch:  24\n","Average train loss: 0.06897371068541695\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  24%|██▍       | 24/100 [1:11:06<4:18:26, 204.04s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.3988894072233462\n","Polarity_Epoch:  25\n","Average train loss: 0.047686518472466174\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  25%|██▌       | 25/100 [1:14:30<4:14:54, 203.92s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4383861425886649\n","Polarity_Epoch:  26\n","Average train loss: 0.04960882494694823\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 100/100 [1:17:54<00:00, 46.74s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.42482226623794417\n","training is done\n","\n","\n","======================= 3 step=========================\n","\n","\n","\n","\n","\n","\n","\n","\n","tokenizing train data\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["We have added 8 tokens\n","loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["end loading\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   0%|          | 0/100 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Polarity_Epoch:  1\n","Average train loss: 0.8022383072560555\n","validation error:  0.6282214481456607\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   1%|          | 1/100 [02:15<3:43:29, 135.45s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  2\n","Average train loss: 0.5724967819099364\n","validation error:  0.5221570585093467\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   2%|▏         | 2/100 [04:31<3:41:29, 135.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  3\n","Average train loss: 0.505646513774991\n","validation error:  0.5195538406960325\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   3%|▎         | 3/100 [06:46<3:39:17, 135.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  4\n","Average train loss: 0.48993772760915916\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   4%|▍         | 4/100 [08:58<3:34:44, 134.21s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5328560572336701\n","Polarity_Epoch:  5\n","Average train loss: 0.5040946425563705\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   5%|▌         | 5/100 [11:10<3:31:11, 133.39s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5842351586697927\n","Polarity_Epoch:  6\n","Average train loss: 0.5319921893839675\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   6%|▌         | 6/100 [13:22<3:28:17, 132.95s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.585120439529419\n","Polarity_Epoch:  7\n","Average train loss: 0.5495276403870728\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   7%|▋         | 7/100 [15:35<3:25:45, 132.75s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5969528948364694\n","Polarity_Epoch:  8\n","Average train loss: 0.5574035956156685\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   8%|▊         | 8/100 [17:47<3:23:22, 132.64s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5995630112543605\n","Polarity_Epoch:  9\n","Average train loss: 0.561950633504526\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   9%|▉         | 9/100 [19:59<3:20:58, 132.51s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.6070058613869489\n","Polarity_Epoch:  10\n","Average train loss: 0.5179180839638177\n","validation error:  0.31869406512408865\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  10%|█         | 10/100 [23:29<3:54:27, 156.31s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  11\n","Average train loss: 0.3548719120751086\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  11%|█         | 11/100 [26:53<4:13:41, 171.03s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5342171455130857\n","Polarity_Epoch:  12\n","Average train loss: 0.32179343954071793\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  12%|█▏        | 12/100 [30:18<4:25:39, 181.13s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.45664106291152684\n","Polarity_Epoch:  13\n","Average train loss: 0.24624374205258823\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  13%|█▎        | 13/100 [33:42<4:32:46, 188.12s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.46248461493577053\n","Polarity_Epoch:  14\n","Average train loss: 0.1926066029731086\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  14%|█▍        | 14/100 [37:06<4:36:38, 193.00s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4953252122147021\n","Polarity_Epoch:  15\n","Average train loss: 0.18313883922957375\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  15%|█▌        | 15/100 [40:30<4:38:07, 196.33s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5343942520592142\n","Polarity_Epoch:  16\n","Average train loss: 0.15932054486965122\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  16%|█▌        | 16/100 [43:54<4:38:10, 198.69s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5641715752776542\n","Polarity_Epoch:  17\n","Average train loss: 0.36485916155231135\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  17%|█▋        | 17/100 [47:20<4:37:35, 200.67s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4468808336536479\n","Polarity_Epoch:  18\n","Average train loss: 0.29328946374957204\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  18%|█▊        | 18/100 [50:44<4:35:40, 201.72s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.49637313469562655\n","Polarity_Epoch:  19\n","Average train loss: 0.2179611914356141\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  19%|█▉        | 19/100 [54:08<4:33:15, 202.42s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4514030011042076\n","Polarity_Epoch:  20\n","Average train loss: 0.19284055831437735\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  20%|██        | 20/100 [57:32<4:30:32, 202.91s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.41055926396907155\n","Polarity_Epoch:  21\n","Average train loss: 0.1744301340184297\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 100/100 [1:00:56<00:00, 36.57s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4755300216961141\n","training is done\n","\n","\n","======================= 4 step=========================\n","\n","\n","\n","\n","\n","\n","\n","\n","tokenizing train data\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["We have added 8 tokens\n","loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["end loading\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   0%|          | 0/100 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Polarity_Epoch:  1\n","Average train loss: 0.8978376717403017\n","validation error:  0.694733618513534\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   1%|          | 1/100 [02:32<4:10:57, 152.09s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  2\n","Average train loss: 0.622471236781338\n","validation error:  0.5417558770430716\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   2%|▏         | 2/100 [04:48<3:52:55, 142.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  3\n","Average train loss: 0.5209484867421277\n","validation error:  0.4814353936204785\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   3%|▎         | 3/100 [07:04<3:45:38, 139.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  4\n","Average train loss: 0.49534554662082\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   4%|▍         | 4/100 [09:16<3:38:44, 136.71s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.49755231129299654\n","Polarity_Epoch:  5\n","Average train loss: 0.5082517621919439\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   5%|▌         | 5/100 [11:28<3:33:55, 135.11s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.49771278567220034\n","Polarity_Epoch:  6\n","Average train loss: 0.511224285612259\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   6%|▌         | 6/100 [13:40<3:30:07, 134.13s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5437173299295338\n","Polarity_Epoch:  7\n","Average train loss: 0.5326988193679032\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   7%|▋         | 7/100 [15:52<3:26:50, 133.45s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5174884620416713\n","Polarity_Epoch:  8\n","Average train loss: 0.5447402906853381\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   8%|▊         | 8/100 [18:05<3:24:06, 133.11s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5772219710297098\n","Polarity_Epoch:  9\n","Average train loss: 0.5398546192544239\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   9%|▉         | 9/100 [20:17<3:21:27, 132.83s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5910337612179941\n","Polarity_Epoch:  10\n","Average train loss: 0.507069246069649\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  10%|█         | 10/100 [23:43<3:53:05, 155.39s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.49253790418764476\n","Polarity_Epoch:  11\n","Average train loss: 0.375158903814473\n","validation error:  0.35284005228037896\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  11%|█         | 11/100 [27:11<4:14:26, 171.53s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  12\n","Average train loss: 0.3012118612481847\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  12%|█▏        | 12/100 [30:35<4:26:13, 181.51s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.35715613445561184\n","Polarity_Epoch:  13\n","Average train loss: 0.2596545544726704\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  13%|█▎        | 13/100 [34:00<4:33:19, 188.50s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.3717337376560624\n","Polarity_Epoch:  14\n","Average train loss: 0.21593741610744122\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  14%|█▍        | 14/100 [37:24<4:37:07, 193.35s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.35834312260052875\n","Polarity_Epoch:  15\n","Average train loss: 0.18380821972461464\n","validation error:  0.34744597966537666\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  15%|█▌        | 15/100 [40:53<4:40:12, 197.80s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  16\n","Average train loss: 0.15359851120617882\n","validation error:  0.33172134414168175\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  16%|█▌        | 16/100 [44:21<4:41:17, 200.93s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  17\n","Average train loss: 0.1210835783395225\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  17%|█▋        | 17/100 [47:45<4:39:29, 202.04s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.3767457217419226\n","Polarity_Epoch:  18\n","Average train loss: 0.0982665423738154\n","validation error:  0.3020051104433246\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  18%|█▊        | 18/100 [51:14<4:38:38, 203.88s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  19\n","Average train loss: 0.0889429051952042\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  19%|█▉        | 19/100 [54:38<4:35:30, 204.08s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.3808323226403445\n","Polarity_Epoch:  20\n","Average train loss: 0.07536955507493567\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  20%|██        | 20/100 [58:02<4:32:12, 204.16s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.38402812565235717\n","Polarity_Epoch:  21\n","Average train loss: 0.07778379704026361\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  21%|██        | 21/100 [1:01:27<4:28:56, 204.26s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.33660978091096405\n","Polarity_Epoch:  22\n","Average train loss: 0.077325690750259\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  22%|██▏       | 22/100 [1:04:51<4:25:35, 204.31s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.35586694816715625\n","Polarity_Epoch:  23\n","Average train loss: 0.06921050739314022\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  23%|██▎       | 23/100 [1:08:16<4:22:12, 204.31s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.379753180993966\n","Polarity_Epoch:  24\n","Average train loss: 0.0639195171565625\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  24%|██▍       | 24/100 [1:11:40<4:18:48, 204.32s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.44125643424616245\n","Polarity_Epoch:  25\n","Average train loss: 0.07552099996055239\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  25%|██▌       | 25/100 [1:15:06<4:15:55, 204.74s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.40197617075357\n","Polarity_Epoch:  26\n","Average train loss: 0.08511021708356972\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  26%|██▌       | 26/100 [1:18:30<4:12:22, 204.63s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.3775589319411665\n","Polarity_Epoch:  27\n","Average train loss: 0.08460629154424901\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  27%|██▋       | 27/100 [1:21:54<4:08:52, 204.55s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.388064651946096\n","Polarity_Epoch:  28\n","Average train loss: 0.06858402087807362\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  28%|██▊       | 28/100 [1:25:19<4:05:20, 204.45s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.3958458552921289\n","Polarity_Epoch:  29\n","Average train loss: 0.0646784193630289\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 100/100 [1:28:43<00:00, 53.24s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4474722026712506\n","training is done\n","\n","\n","======================= 5 step=========================\n","\n","\n","\n","\n","\n","\n","\n","\n","tokenizing train data\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["We have added 8 tokens\n","loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["end loading\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   0%|          | 0/100 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Polarity_Epoch:  1\n","Average train loss: 0.7127576670525305\n","validation error:  0.5606522967940882\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   1%|          | 1/100 [02:27<4:03:07, 147.35s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  2\n","Average train loss: 0.5435290687238837\n","validation error:  0.4883261105339778\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   2%|▏         | 2/100 [04:43<3:50:03, 140.85s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  3\n","Average train loss: 0.49885312339355203\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   3%|▎         | 3/100 [06:55<3:41:22, 136.93s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5028986748504011\n","Polarity_Epoch:  4\n","Average train loss: 0.5007252002254202\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   4%|▍         | 4/100 [09:08<3:36:12, 135.13s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.500642974248254\n","Polarity_Epoch:  5\n","Average train loss: 0.5481062334991246\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   5%|▌         | 5/100 [11:20<3:32:18, 134.08s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5422924330065909\n","Polarity_Epoch:  6\n","Average train loss: 0.5456132454910791\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   6%|▌         | 6/100 [13:32<3:29:07, 133.48s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5341603216764174\n","Polarity_Epoch:  7\n","Average train loss: 0.5506767272912516\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   7%|▋         | 7/100 [15:45<3:26:17, 133.09s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5470484323848627\n","Polarity_Epoch:  8\n","Average train loss: 0.5756044729394083\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   8%|▊         | 8/100 [17:57<3:23:43, 132.86s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.5603292939302168\n","Polarity_Epoch:  9\n","Average train loss: 0.5197966459447332\n","validation error:  0.3453649135772139\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:   9%|▉         | 9/100 [21:27<3:58:00, 156.93s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  10\n","Average train loss: 0.3846232137613745\n","validation error:  0.3425487197911073\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  10%|█         | 10/100 [24:55<4:19:12, 172.81s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  11\n","Average train loss: 0.3388797466984181\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  11%|█         | 11/100 [28:20<4:30:40, 182.48s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4136222470551729\n","Polarity_Epoch:  12\n","Average train loss: 0.28143112614371607\n","validation error:  0.33164646975254936\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  12%|█▏        | 12/100 [31:48<4:39:09, 190.34s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  13\n","Average train loss: 0.21896494275849002\n","validation error:  0.3185590969423126\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  13%|█▎        | 13/100 [35:16<4:43:52, 195.78s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","polarity_model best model updated.\n","Polarity_Epoch:  14\n","Average train loss: 0.16123321826595732\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  14%|█▍        | 14/100 [38:41<4:44:28, 198.47s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.40116105280130315\n","Polarity_Epoch:  15\n","Average train loss: 0.13699971131784675\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  15%|█▌        | 15/100 [42:05<4:43:43, 200.27s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4485059753611782\n","Polarity_Epoch:  16\n","Average train loss: 0.11361622864652689\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  16%|█▌        | 16/100 [45:30<4:42:07, 201.51s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4033175094334997\n","Polarity_Epoch:  17\n","Average train loss: 0.09892031459416124\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  17%|█▋        | 17/100 [48:54<4:40:00, 202.42s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4253676134333211\n","Polarity_Epoch:  18\n","Average train loss: 0.08843673999942778\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  18%|█▊        | 18/100 [52:19<4:37:30, 203.05s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.3791522452129835\n","Polarity_Epoch:  19\n","Average train loss: 0.07910626019199787\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  19%|█▉        | 19/100 [55:43<4:34:43, 203.51s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.3944019245621013\n","Polarity_Epoch:  20\n","Average train loss: 0.201480397763425\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  20%|██        | 20/100 [59:09<4:32:18, 204.23s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.42897726108908263\n","Polarity_Epoch:  21\n","Average train loss: 0.14620550129752244\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  21%|██        | 21/100 [1:02:34<4:29:04, 204.36s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.48549459141213447\n","Polarity_Epoch:  22\n","Average train loss: 0.09305345638974742\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  22%|██▏       | 22/100 [1:05:58<4:25:43, 204.41s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.41004821943045644\n","Polarity_Epoch:  23\n","Average train loss: 0.09492749050840711\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  23%|██▎       | 23/100 [1:09:23<4:22:20, 204.42s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.4113460367447452\n","Polarity_Epoch:  24\n","Average train loss: 0.07238054179933613\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 100/100 [1:12:48<00:00, 43.68s/it]"]},{"output_type":"stream","name":"stdout","text":["validation error:  0.3929034569361982\n","training is done\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["train_sentiment_analysis()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPLJxhcGW-Tj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0njSTIALJ_bK"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sBmMqUEEYuck"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}